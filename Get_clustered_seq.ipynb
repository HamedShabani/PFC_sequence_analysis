{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook loads the clusterd sequences (resutls from \"Read_and_cluster.ipynb\") and merges data of chosen behavioral epochs (merge sampling, outward, reward) in order to  perform furthur repaly analysis using bayesina decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illustration of the use of these functions\n",
      " Mask indexes (burst array indexes): \n",
      " [2, 10, 50] \n",
      "Mask indexes expanded to its 2 neighbours: \n",
      " [ 0  1  2  3  4  8  9 10 11 12 48 49 50 51 52] \n",
      "Input indexes (array indexes of the positions y or spike positions ysp)\n",
      " [3, 7, 12, 30, 51, 100] \n",
      "Input indexes excluding those in the set of mask indexes\n",
      " [  7  30 100]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.special import factorial\n",
    "from scipy.stats import spearmanr\n",
    "import pftools as pf\n",
    "import configparser\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "# Initialize the configuration parser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the configuration file\n",
    "#config.read('config.ini')\n",
    "\n",
    "# Get the data folder path from the config file\n",
    "#savefolder= config['paths']['savefolder']\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 16  # You can adjust the font size as needed\n",
    "plt.rcParams['ytick.labelsize'] = 16  # You can adjust the font size as needed\n",
    "import mtools as mot\n",
    "import pickle\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "from pathlib import Path\n",
    "onfig = configparser.ConfigParser()\n",
    "# Detect base directory\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent  # For scripts\n",
    "except NameError:\n",
    "    BASE_DIR = Path.cwd()  # For Jupyter Notebooks\n",
    "\n",
    "# Move one level up\n",
    "BASE_DIR = BASE_DIR.parent\n",
    "\n",
    "# Load config.ini\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.join(os.getcwd(), \"config.ini\"))\n",
    "\n",
    "# Construct full paths using pathlib and ensure they end with a separator\n",
    "skeletonsfolder = str((BASE_DIR / config[\"paths\"][\"skeletonsfolder\"]).resolve()) + os.sep\n",
    "savefolder = str((BASE_DIR / config[\"paths\"][\"savefolder\"]).resolve()) + os.sep\n",
    "datafolder = str((BASE_DIR / config[\"paths\"][\"datafolder\"]).resolve()) + os.sep\n",
    "\n",
    "# Print paths to verify\n",
    "print(\"Base Directory:\", BASE_DIR)\n",
    "print(\"Skeletons Folder:\", skeletonsfolder)\n",
    "print(\"Save Folder:\", savefolder)\n",
    "print(\"Data Folder:\", datafolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_names = {\n",
    "    'sampling_L': 0,\n",
    "    'sampling_R': 1,\n",
    "    'outward_L': 2,\n",
    "    'outward_R': 3,\n",
    "    'reward_L': 4,\n",
    "    'reward_R': 5,\n",
    "    'inward_L': 6,\n",
    "    'inward_R': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to get the merged data of sampling, outward and reward for burst replay analysis \n",
    "cell_types='All'\n",
    "descriotor='No_chunk_0.5s_transients'\n",
    "for fol in ['478','481','483','485']:\n",
    "\n",
    "\n",
    "    filename = fol+'Sesseion_info_All AllNo_chunk_0.5s_transients'\n",
    "\n",
    "\n",
    "    data_all_tasks = np.load(join(savefolder, filename), allow_pickle=True)\n",
    "    sess_info= data_all_tasks['sess_info']\n",
    "    #Masks= data_all_tasks['Masks']# this mask does not include mask of correct trials of single cells\n",
    "\n",
    "\n",
    "    filename_mask = fol+'Mask_with_correct_cells'\n",
    "    Masks_ = np.load(join(savefolder, filename_mask), allow_pickle=True)# i added the correct masks for single cell data recently\n",
    "    Masks=Masks_[0]\n",
    "\n",
    "\n",
    "    #data_info=np.load(savefolder+fol+'data_all_sessions'+cell_types+'_'+ descriotor+'newodrer', allow_pickle=True)\n",
    "    session_mask=Masks_[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    speed_thr=0\n",
    "    # add the mask for speed. speed threshold is set to 5.\n",
    "    smooth_speed=mot.smooth_signal(sess_info['speed'], 13)# moving average over .5  second\n",
    "    Masks['speed_seq']=np.asarray(smooth_speed)[sess_info['id_peaks']]>speed_thr\n",
    "    Masks['speed']=smooth_speed>speed_thr\n",
    "\n",
    "\n",
    "    # select the data you need. Sessen number, epeoch, .... Selected data will be saved with corresposing name. Inward and outward data will be used by place filed code. \n",
    "    sessin_numbers=np.arange(len(session_mask))#[4,5,6,7][0,1,2,3]##np.arange(len(session_mask))\n",
    "    #sessin_numbers=[6]\n",
    "    #sessin_numbers=[0,1,2,3,4,5,6,7] # soecify which session you want to work with\n",
    "    #celid=23# number of sample cell to show in the plot\n",
    "\n",
    "    #cond_number=[3] # conditon name (outwards)\n",
    "    #cond_number=[8,9,10,11] # inwards\n",
    "    #cond_number=[0,1] # sampling\n",
    "    #cond_number=[6,7] # reward\n",
    "    for con_number in ([3],):#([1,3,5],[0,2,4],[0,2,4,1,3,5]):# to save only otward data use 2 and 3 for left and right runs\n",
    "            \n",
    "        trial_type=1 # 1 is correct       0 is failed\n",
    "\n",
    "        if trial_type==1:\n",
    "            type_name='correct'\n",
    "        elif trial_type==0:\n",
    "            type_name='failed'\n",
    "\n",
    "\n",
    "\n",
    "        phase=None#None#None#,1 # 0 is learning,    1 is learned,  None is both\n",
    "        if phase==None:\n",
    "            phase_name='all'\n",
    "        elif phase==0:\n",
    "            phase_name='learning'\n",
    "        elif phase==1:\n",
    "            phase_name='learned'\n",
    "                \n",
    "\n",
    "\n",
    "        # odd_even=1# even trials\n",
    "        # run_data_e=mot.apply_masks(sess_info,Masks,cond_number,cond_names,sessin_numbers,odd_even,session_mask,trial_type,phase)\n",
    "        # #plt.title(run_data_e['sess_name']+' (even) ('+ run_data_e['phase_name']+') ('+run_data_e['cond_name'] +')')\n",
    "\n",
    "        # odd_even=0# odd trials\n",
    "        # run_data_o=mot.apply_masks(sess_info,Masks,cond_number,cond_names,sessin_numbers,odd_even,session_mask,trial_type,phase)\n",
    "        # #plt.title(run_data_e['sess_name']+' (odd) ('+ run_data_e['phase_name']+') ('+run_data_e['cond_name'] +')')\n",
    "\n",
    "        odd_even=None# all trials\n",
    "        run_data_all=mot.apply_masks_test(sess_info,Masks,con_number,cond_names,sessin_numbers,odd_even,session_mask,trial_type,phase)\n",
    "\n",
    "\n",
    "\n",
    "        name_of_conds=' '.join([xn for xn,x in cond_names.items() if x in con_number])\n",
    "\n",
    "        run_data_all['template']=sess_info['template']\n",
    "        # with open(savefolder+fol+animal_direction+'_'+ phase_name+'_'+type_name+'_'+descriotor+'_'+cell_types+'test_neworder_with_templates','wb') as f:\n",
    "        #     pickle.dump(dict(run_data_all), f)   \n",
    "        #plt.title(run_data_e['sess_name']+' (all) ('+ run_data_e['phase_name']+') ('+run_data_e['cond_name'] +')')\n",
    "        with open(savefolder+fol+name_of_conds+'_'+ phase_name+'_'+type_name,'wb') as f:\n",
    "            pickle.dump(dict(run_data_all), f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
